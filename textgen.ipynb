{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30bca62e-83e6-453d-9ecc-e91febc73edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aitextgen.TokenDataset import TokenDataset\n",
    "from aitextgen.tokenizers import train_tokenizer\n",
    "from aitextgen.utils import GPT2ConfigCPU\n",
    "from aitextgen import aitextgen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2fce227-6c3a-4071-9009-6ffdbd57ecbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"lyrics.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9704793b-3115-4bd2-be50-469c2c791c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train a custom BPE Tokenizer on the downloaded text\n",
    "# This will save one file: `aitextgen.tokenizer.json`, which contains the\n",
    "# information needed to rebuild the tokenizer.\n",
    "train_tokenizer(file_name)\n",
    "tokenizer_file = \"aitextgen.tokenizer.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7d963f2-fe48-40ab-9a84-f209e9d8f599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT2ConfigCPU is a mini variant of GPT-2 optimized for CPU-training\n",
    "# e.g. the # of input tokens here is 64 vs. 1024 for base GPT-2.\n",
    "config = GPT2ConfigCPU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4ee4696-7371-4945-973d-757bf3e2d87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate aitextgen using the created tokenizer and config\n",
    "ai = aitextgen(tokenizer_file=tokenizer_file, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c326021-6532-4146-a901-85aa74ed0db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9f3c36aace145f3a4edd82821ab134e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|                                                   | 0/404 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# You can build datasets for training by creating TokenDatasets,\n",
    "# which automatically processes the dataset with the appropriate size.\n",
    "data = TokenDataset(file_name, tokenizer_file=tokenizer_file, block_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7688d64-d51b-42cd-a74f-9435abfeae12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pytorch_model.bin already exists in /trained_model and will be overwritten!\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d44b670e5bbd48b1a1f8d46f75694502",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|                                                 | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\u001b[1m5,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m5,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      ", my hand in mine.I've brother you go on, I know I'm so high.I'm so right where you're going to a will sad.Same much you a long yeh,I'm la la laSha la la lazy song be in the sun begin' here\n",
      "==========\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=10000` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10,000 steps reached: saving model to /trained_model\u001b[0m\n",
      "\u001b[1m10,000 steps reached: generating sample texts.\u001b[0m\n",
      "==========\n",
      ",Yeah,Oo, tell me that's all I want to married, and I want you tired,There's nothing shakingBut the leaves on the realikingBut the trees.Oh how the treesday I still can't.I never know that you have a fool\n",
      "==========\n"
     ]
    }
   ],
   "source": [
    "# Train the model! It will save pytorch_model.bin periodically and after completion to the `trained_model` folder.\n",
    "# On a 2020 8-core iMac, this took ~25 minutes to run.\n",
    "ai.train(data, batch_size=8, num_steps=10000, generate_every=5000, save_every=5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab23ac27-a573-4119-8be0-692473d054e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6860aefa-6be5-4468-a75e-9322c56447ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\n",
      "Temperature: 0.7\n",
      "####################\n",
      ",And I find better blues.Told me, I'll be some tad the girl for the long kissie,Deep inse and I cannothes, like that youDo return, re of when I tell you, I.I'll get to moing to you\n",
      "==========\n",
      ", everywhereSlimplimpant froature? Dre you see how you rh,You'll be thereWhen I'm with you treat me like a sling with you,Then I'll know that I'll close to you will hitain\n",
      "==========\n",
      "liesOnce there was a way to get back homeSleep pretty darling do not cryAnd I will sing a left of lullabyeften the doorAnd send ourousanding a wayYou bending a rulBut she still the breaks\n",
      "####################\n",
      "Temperature: 1.0\n",
      "####################\n",
      ", yeah.\n",
      "When she is all the days means of hands off my baby.Ain't a-gonna,I ain't a sy,See darling, if you don't you want to say goodbye,Well, I say goodbye, I say goodbye and I say hello.\n",
      "==========\n",
      ", now.Turns turing to moonne, tents somebody pelphon,Deep soon,Deep in the heart has come.Woken heart at the Deep in the groundAnd.Won you sout roo.S\n",
      "==========\n",
      ", I believe me.Till she's all the world, she lather misfle looked at meShe is what I want herself to knowShe pride,I'm gonna love her and cat her.She as can't she could,'cause her lies.Yes she al\n",
      "####################\n",
      "Temperature: 1.2\n",
      "####################\n",
      "now gonna since you know I'll forget you told meYou know I love to you anyone can.Tell me,Sew togetist and, think,Gonna do very as you do you.I'll make it in when my love for ever,Tomise,When you got me\n",
      "==========\n",
      "In my life could saint-when we live livedass out)Well, long are now. (lookshagh)You workinin' byuumcome your cha olders out)I am woo go.To get my, I'm\n",
      "==========\n",
      ",Please don't ever change.Please don't ever say goodbye, don't ever ever say goodbye.\n",
      "Be don't ever want goodbye,Just trav''t know goodbye,I don't conozy the wayppy hippy hippy shake.Ooon are.Per if you want\n"
     ]
    }
   ],
   "source": [
    "ai.generate_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86af7f67-5913-401a-b5f4-19588677701d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mRingo Star isn't even the best drummer in The Beatles because\u001b[0m every dreams of june we can war on the junct the might they see it is the rows and they seemous.\n",
      "==========\n",
      "\u001b[1mRingo Star isn't even the best drummer in The Beatles because\u001b[0m game besame be layedAair of sweet dreams that's nerveIf I ask you There be no am changing the\n",
      "==========\n",
      "\u001b[1mRingo Star isn't even the best drummer in The Beatles because\u001b[0m everyone smileYou don't know the learn't be badI'm the kind of that girl I can't know the same.If there's any\n",
      "==========\n",
      "\u001b[1mRingo Star isn't even the best drummer in The Beatles because\u001b[0m happens, she's nobody told me you,A cutbut off your head.Well she's gonna be alrightYou know I told you about\n",
      "==========\n",
      "\u001b[1mRingo Star isn't even the best drummer in The Beatles because\u001b[0m every nowShe I've been in her mind abitsaneYou're the kind of girls make me feel a foolIt's the kind of mind a bir\n",
      "==========\n",
      "\u001b[1mRingo Star isn't even the best drummer in The Beatles because\u001b[0m I michGirl, you go, you know it ain't,You know it ain't easy seredWrit you know it againOo,\n",
      "==========\n",
      "\u001b[1mRingo Star isn't even the best drummer in The Beatles because\u001b[0m everyone the cuss and fipsion.They say that you don't really matn't understand.Well you know it's my mind\n",
      "==========\n",
      "\u001b[1mRingo Star isn't even the best drummer in The Beatles because\u001b[0m every girl I lovely than the fightCreatch little whimpse and I mistake a lovering I take my friend to hear,\n",
      "==========\n",
      "\u001b[1mRingo Star isn't even the best drummer in The Beatles because\u001b[0m every obladi oblada life goes on braLala how you know you know you know you have a who of that you and you've\n",
      "==========\n",
      "\u001b[1mRingo Star isn't even the best drummer in The Beatles because\u001b[0m I can't buy me love is here againHey, don't be a real love you will ask you, baby don't be a real? You got that l\n"
     ]
    }
   ],
   "source": [
    "ai.generate(10, prompt=\"Ringo Star isn't even the best drummer in The Beatles because\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e295730a-e878-476f-9ed0-f0f0c93dc288",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
